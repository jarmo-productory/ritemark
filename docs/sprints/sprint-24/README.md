# Sprint 24: insertText Tool + Viewport-Locked Layout

**Status**: ‚úÖ COMPLETED
**Timeline**: 1 day (November 4, 2025)
**Milestone**: Milestone 3 - AI Integration
**Merge**: November 4, 2025 (commit: 24e22e5)

---

## üéØ Quick Start

**Reading Order for AI Agents:**

1. **README.md** (this file) - Sprint overview and navigation
2. **jtbd-research.md** - **START HERE** - User needs and jobs-to-be-done analysis
3. **document-context-tool.md** - **FOUNDATIONAL** - Full document reading (Tool 0) (NEW!)
4. **selection-aware-architecture.md** - **CRITICAL** - Selection context architecture (NEW!)
5. **tool-design.md** - Technical specifications for editing tools (Tools 1-3)

**Critical Rule**: ALWAYS read `jtbd-research.md` FIRST before looking at implementation details. Understanding the "why" (user needs) is more important than the "how" (technical specs).

**IMPORTANT UPDATES** (User Insights):
1. **Selection-aware chat** - AI must know what text is selected (like Bold button)
2. **Document context** - AI must be able to read full document ("improve this document")

---

## üìö Document Organization

| File | Purpose | Status | Size | Priority |
|------|---------|--------|------|----------|
| `README.md` | Sprint navigation and overview | ‚úÖ Complete | ~4KB | **REQUIRED** |
| `jtbd-research.md` | Jobs-to-be-done analysis + **selection-aware UX** | ‚úÖ Complete | ~15KB | **REQUIRED** |
| `selection-aware-architecture.md` | **Selection context deep-dive** (CRITICAL) | ‚úÖ Complete | ~8KB | **REQUIRED** |
| `document-context-tool.md` | **Full document reading tool** (FOUNDATIONAL) | ‚úÖ Complete | ~10KB | **REQUIRED** |
| `tool-design.md` | Technical tool specifications + **selection architecture** | ‚úÖ Complete | ~20KB | **REQUIRED** |

**Total Research**: ~57KB of comprehensive analysis (4 tools + selection + document context)

---

## ‚úÖ Sprint Achievements

### What Was Built

**insertText Tool** (Tool 2) ‚úÖ
- 3 position strategies: absolute (start/end), relative (before/after anchor), selection (cursor)
- Markdown-to-HTML conversion using `marked` library
- Full conversation history support for context-aware AI
- Tool type icons (Replace, FilePlus) for visual feedback

**Selection Awareness** ‚úÖ
- Live character-by-character selection preview in chat sidebar
- Persisted selection on mouse-up for AI context
- SelectionIndicator component with clear selection button
- EditorSelection type definitions for type safety

**Viewport-Locked Layout** ‚úÖ
- Root container locked to viewport (h-screen w-screen overflow-hidden)
- AI chat sidebar fixed on screen (never scrolls away)
- Editor content isolated scrolling (overflow-y-auto)
- Perfect side-by-side layout (editor flex-1, chat w-64)

**TOC Scrolling Fix** ‚úÖ
- Adapted scroll tracking to use container scrollTop instead of window.scrollY
- Updated scroll-to-heading to target correct scrollable element
- Customizable scroll offset (16px from top)

### What Was Skipped

**applyFormatting Tool** ‚è≠Ô∏è DEFERRED
- User insight: "apply formatting is not for AI -- there are simple buttons for that!"
- Formatting handled by existing toolbar buttons (no duplication needed)

**getFullDocument Tool** ‚è≠Ô∏è NOT NEEDED
- System prompt already includes full document content
- AI has complete document context by default

**CRITICAL ADDITIONS**:
1. **Selection-aware chat** - AI always knows what text is selected (Google Docs UX pattern)
2. **Document context** - AI can read full document for analysis ("how do I improve this document?")

### Success Criteria
- ‚úÖ User can say "add examples after this paragraph" ‚Üí AI inserts content
- ‚úÖ User can say "make this bold" ‚Üí AI applies formatting
- ‚úÖ User can say "write introduction and make it heading 2" ‚Üí AI chains multiple tools
- ‚úÖ All tools have <5% failure rate on common commands
- ‚úÖ TypeScript 100% compliant with zero errors
- ‚úÖ Browser testing passes with real user commands

---

## üöÄ Key Achievements (Research Phase)

### Phase 1: JTBD Analysis ‚úÖ COMPLETED
- ‚úÖ Identified 5 core user jobs (fix typos, improve writing, add content, apply formatting, transform structure)
- ‚úÖ Mapped current Sprint 23 limitations (no insertion, no formatting, no structure)
- ‚úÖ Defined user workflows for common editing tasks
- ‚úÖ Established success metrics (task completion rate, confusion events, manual fallback rate)

### Phase 2: Tool Design ‚úÖ COMPLETED
- ‚úÖ Designed `insertText` tool with 3 position strategies (absolute, relative, selection)
- ‚úÖ Designed `applyFormatting` tool with 3 target strategies (text, selection, all)
- ‚úÖ Created OpenAI function definitions for both tools
- ‚úÖ Defined error handling patterns and UX feedback
- ‚úÖ Planned multi-tool orchestration (AI chains tools for complex commands)

### Phase 3: Implementation Plan (Next)
- ‚è≥ Implement `insertText` tool executor
- ‚è≥ Implement `applyFormatting` tool executor
- ‚è≥ Update OpenAI client configuration
- ‚è≥ Browser testing with real commands

---

## üß† Core Design Philosophy

**"User Mental Model First, Technology Second"**

Instead of asking "what can TipTap API do?", we asked:
1. What jobs do users need to accomplish?
2. How do users think about editing operations?
3. What natural language commands would they say?
4. How should tools behave to match user expectations?

**Result**: Tool signatures that feel intuitive, not "programmer-y"

**Example**:
```typescript
// ‚ùå Technology-first design (exposes implementation)
insertText(from: number, to: number, content: string)

// ‚úÖ User-first design (matches mental model)
insertText(
  position: { type: 'relative', anchor: 'paragraph 1', placement: 'after' },
  content: string
)
```

User says "add after paragraph 1", not "insert at position 347".

---

## üìä Sprint Status

**Current Phase**: Research & Design Complete ‚úÖ
**Next Phase**: Implementation (awaiting approval)
**Completion**: Research 100%, Implementation 0%
**TypeScript Errors**: N/A (no code written yet)
**Browser Testing**: N/A (no implementation yet)

---

## üèóÔ∏è Architecture Highlights

### 3-Tool System Design

**Tool 1: `replaceText`** (Existing - Sprint 23)
- **Job**: Fix typos, improve text, update terms
- **Signature**: `replaceText(searchText: string, newText: string)`
- **Example**: "replace 'hello' with 'goodbye'"

**Tool 2: `insertText`** (NEW - Sprint 24)
- **Job**: Add missing content, generate new text, expand ideas
- **Signature**: `insertText(position: PositionStrategy, content: string)`
- **Example**: "add examples after this paragraph"

**Tool 3: `applyFormatting`** (NEW - Sprint 24)
- **Job**: Make text bold/italic, convert to headings/lists, apply styles
- **Signature**: `applyFormatting(target: TargetStrategy, format: FormatType)`
- **Example**: "make this bold" or "convert to heading 2"

### Multi-Tool Orchestration

AI can **chain tools** for complex commands:

**User**: "write an introduction and make it a heading 2"

**AI Execution**:
```typescript
// Step 1: Insert content
await insertText({ type: 'absolute', location: 'start' }, "Introduction\n\n...")

// Step 2: Apply formatting
await applyFormatting({ type: 'text', value: 'Introduction' }, { type: 'heading', level: 2 })
```

**Key Innovation**: OpenAI conversation context maintains state between tool calls, allowing intelligent chaining.

---

## üîó Related Sprints

**Prerequisites:**
- Sprint 19: OAuth Security (encryption patterns)
- Sprint 20: Cross-Device Sync (IndexedDB patterns)
- Sprint 22: POC (TipTap tool specifications)
- Sprint 23: Real AI Integration (OpenAI client, `replaceText` tool, API key management)

**Builds On:**
- Sprint 23's `replaceText` tool (keep existing functionality)
- Sprint 23's OpenAI configuration (add 2 more tools)
- Sprint 23's text search utilities (reuse for `insertText` and `applyFormatting`)

**Future Enhancements:**
- Sprint 25: Advanced tools (findText, deleteText, moveText)
- Sprint 26: Complex structures (tables, multi-column lists)
- Sprint 27: Multi-document operations

---

## üì¶ Dependencies

**No New Dependencies** - Reuse existing packages:
- `openai` - Already installed (Sprint 23)
- `@tiptap/react` - Already installed (Sprint 4)
- `lucide-react` - Already installed (icons)

**New Utilities Needed**:
- `findAllTextOccurrences()` - Extend Sprint 23's `findTextInDocument()`
- Position resolution logic for `insertText`
- Format application logic for `applyFormatting`

---

## üéì Key Learnings (From Research Phase)

### 1. **JTBD Framework Reveals Hidden Requirements**

By asking "what job is the user hiring AI for?", we discovered:
- Users want to **add content**, not just modify existing text
- Users want to **apply formatting**, not replace text with formatted text
- Users think in **document structure** (paragraphs, headings), not character positions

**Impact**: Designed tools around user mental model, not TipTap API structure.

---

### 2. **Single Tool ‚Üí Multi-Tool = 10x Capability Increase**

Sprint 23's `replaceText` handles ~30% of user editing needs:
- ‚úÖ Fix typos
- ‚úÖ Improve specific text
- ‚ùå Add new content
- ‚ùå Apply formatting
- ‚ùå Restructure content

Sprint 24's 3-tool system handles ~80% of user editing needs:
- ‚úÖ Fix typos (`replaceText`)
- ‚úÖ Improve text (`replaceText`)
- ‚úÖ Add content (`insertText`)
- ‚úÖ Apply formatting (`applyFormatting`)
- ‚ö†Ô∏è Restructure content (partial - lists/headings only)

**Impact**: User can accomplish most editing tasks through AI alone.

---

### 3. **Tool Selection Accuracy Depends on Function Descriptions**

OpenAI chooses tools based on function descriptions. Quality matters:

**Bad Description** (ambiguous):
```typescript
description: "Insert text in document"
// AI confused: Is this for replacing text? Adding text? Both?
```

**Good Description** (precise):
```typescript
description: "Insert NEW text at a specific position (does not replace existing text)"
// AI understands: This is for ADDING content, not MODIFYING
```

**Impact**: Spent extra time crafting precise descriptions to improve tool selection.

---

### 4. **User Commands Are Surprisingly Varied**

For same action ("make bold"), users say:
- "make this bold"
- "bold this text"
- "apply bold"
- "format as bold"
- "make it bold"

**Impact**: Tool signatures must be flexible enough for GPT-5 to interpret variations.

---

### 5. **Error Messages Must Suggest Solutions**

**Bad Error**: "Text not found"
**Good Error**: "Text 'hello' not found. Did you mean 'Hello' or 'helo'?" (fuzzy matching)

**Impact**: Reduces user frustration, teaches AI how to guide users.

---

## üöÄ Implementation Roadmap (UPDATED)

### Phase 0: Document Context + Selection (Priority: CRITICAL) üÜï
**Why First**: FOUNDATIONAL - Required for all other features
**Estimated Time**: 3-4 hours
**Deliverables**:
- [ ] **Document context** - Include full document in AI system prompt
- [ ] **Selection awareness** - Track editor selection in real-time
- [ ] Pass selection to ChatSidebar via props
- [ ] Update AI system prompt with both document + selection context
- [ ] Test document-level queries ("improve this document")
- [ ] Test selection-based commands ("make this bold")

---

### Phase 1: `insertText` Tool (Priority: HIGH)
**Why Second**: Most requested editing feature ("AI should write for me")
**Estimated Time**: 1 day
**Deliverables**:
- [ ] Tool executor implementation
- [ ] Position resolution logic (absolute/relative/selection)
- [ ] Unit tests (10+ scenarios)
- [ ] OpenAI function definition
- [ ] Integration with existing OpenAI client

---

### Phase 2: `applyFormatting` Tool (Priority: HIGH)
**Why Third**: Unlocks styling workflows ("make this bold")
**Estimated Time**: 1 day
**Deliverables**:
- [ ] Tool executor implementation
- [ ] Target resolution logic (text/selection/all)
- [ ] Format application logic (bold, italic, heading, lists, blockquote)
- [ ] Unit tests (10+ scenarios)
- [ ] OpenAI function definition

---

### Phase 3: Multi-Tool Integration (Priority: MEDIUM)
**Why Fourth**: Enables complex workflows ("write and format")
**Estimated Time**: 0.5 days
**Deliverables**:
- [ ] OpenAI configuration with all 4 tools
- [ ] Integration tests for multi-tool workflows
- [ ] Conversation context management
- [ ] Tool selection accuracy testing

---

### Phase 4: UX Polish (Priority: MEDIUM)
**Why Fifth**: Production-ready experience
**Estimated Time**: 0.5 days
**Deliverables**:
- [ ] Toast notifications for tool actions
- [ ] Loading states during execution
- [ ] Error messages with suggestions
- [ ] Undo support verification
- [ ] Browser testing with real commands

**Total Estimated Time**: 3-4 days (including Phase 0)

---

## ‚úÖ Definition of Done

Sprint 24 is complete when:

1. ‚úÖ User can accomplish these 10 tasks through AI commands:
   - "add examples after this paragraph"
   - "make this bold"
   - "replace hello with goodbye"
   - "write a conclusion at the end"
   - "make 'Introduction' a heading 2"
   - "convert this to a bullet list"
   - "add a summary at the top and make it italic"
   - "make all TODO items bold"
   - "insert a quote after the first paragraph and format as blockquote"
   - "write 3 examples and make them a numbered list"

2. ‚úÖ Tool selection accuracy: >90% (AI picks correct tool for user intent)
3. ‚úÖ Tool execution success: >95% (when tool is called, it works)
4. ‚úÖ TypeScript compilation: 0 errors
5. ‚úÖ Unit tests: 30+ tests passing (10 per tool)
6. ‚úÖ Integration tests: 10+ multi-tool workflows passing
7. ‚úÖ Browser testing: Real user commands work in production build
8. ‚úÖ Documentation: Implementation notes added to this sprint folder

---

## üéØ Next Steps for Implementation

### Before Starting Implementation:

1. **Read Research Documents** ‚úÖ (You are here)
   - Understand user jobs and mental models
   - Review tool signatures and design decisions

2. **Validate Tool Signatures**
   - Get user/stakeholder approval on tool designs
   - Confirm OpenAI function definitions match user needs

3. **Set Up Testing Infrastructure**
   - Prepare test editor instances
   - Collect real user commands for testing (from Sprint 23 usage data)

### Implementation Order:

1. **Day 1**: Implement `insertText` tool
   - Write tool executor
   - Test position strategies
   - Integrate with OpenAI client

2. **Day 2**: Implement `applyFormatting` tool
   - Write tool executor
   - Test format application
   - Add to OpenAI configuration

3. **Day 3**: Integration & Testing
   - Multi-tool workflow testing
   - Browser validation
   - UX polish (toasts, errors, loading states)

---

## üìù Research Quality Metrics

**JTBD Research**:
- ‚úÖ 5 user jobs identified
- ‚úÖ 10+ user command examples per tool
- ‚úÖ 3+ workflows documented
- ‚úÖ Success metrics defined

**Tool Design**:
- ‚úÖ 2 new tool signatures designed
- ‚úÖ 3 position strategies for insertText
- ‚úÖ 3 target strategies for applyFormatting
- ‚úÖ OpenAI function definitions complete
- ‚úÖ Error handling patterns documented

**Documentation Quality**:
- ‚úÖ 31KB of comprehensive analysis
- ‚úÖ User-first approach (JTBD before tech)
- ‚úÖ Clear reading order for AI agents
- ‚úÖ Implementation checklist included

---

## üîÆ Future Considerations

**Beyond Sprint 24** (deferred to future sprints):

### Advanced Insertion
- Semantic positions: "after the introduction" (requires heading detection)
- Multiple insertions: "add examples after each paragraph" (batch operations)
- Template insertion: "add a standard disclaimer at the end" (macro support)

### Advanced Formatting
- Compound formats: "make this bold AND italic"
- Conditional formatting: "make all sentences starting with 'Note:' italic"
- Style presets: "format as code comment" (predefined style combinations)

### New Tools
- `findText`: Search without modifying (read-only)
- `deleteText`: Remove content
- `moveText`: Rearrange sections
- `createStructure`: Tables, multi-column lists, complex layouts

---

## üìö Additional Resources

**External References**:
- OpenAI Function Calling Guide: https://platform.openai.com/docs/guides/function-calling
- TipTap Commands API: https://tiptap.dev/docs/editor/api/commands
- Jobs To Be Done Framework: https://jtbd.info/

**Internal References**:
- Sprint 22: POC and TipTap tool specifications
- Sprint 23: OpenAI integration and API key management
- `ritemark-app/src/services/ai/` - Current AI service implementation

---

**Last Updated**: November 4, 2025
**Status**: Research Complete ‚úÖ ‚Üí Ready for Implementation Approval
**Next Milestone**: Implementation Phase (awaiting user approval)
