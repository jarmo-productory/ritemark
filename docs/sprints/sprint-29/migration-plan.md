# Vercel AI SDK Migration Plan

## üéØ Executive Summary

**Decision**: ‚úÖ **PROCEED** with Vercel AI SDK migration

**Strategy**: Incremental migration with feature flag and gradual rollout

**Timeline**: 4 sprints (Sprints 30-33)

**Risk Level**: üü° Medium (mitigated by incremental approach)

## üìã Migration Phases

### Phase 1: Foundation Setup (Sprint 30)
**Goal**: Install dependencies and create backend infrastructure

#### Tasks
1. **Install Vercel AI SDK**
   ```bash
   npm install ai @ai-sdk/openai
   ```

2. **Create Netlify Function**
   - File: `netlify/functions/ai-chat.ts`
   - Implement `streamText` with OpenAI
   - Add request validation
   - Error handling and logging

3. **Environment Variables**
   - Verify `OPENAI_API_KEY` in Netlify
   - Add to `.env.local` for local development
   - Document in README

4. **Feature Flag Setup**
   - Add `USE_VERCEL_AI_SDK` to settings
   - Default: `false` (disabled)
   - Toggleable via settings UI (dev only)

5. **Testing Infrastructure**
   - Mock `useChat` hook for tests
   - Test Netlify function locally
   - Integration tests with real API

**Deliverables:**
- ‚úÖ Netlify function deployed
- ‚úÖ Feature flag implemented
- ‚úÖ Tests passing

**Success Criteria:**
- [ ] `POST /api/ai-chat` responds with streaming text
- [ ] Feature flag toggles between implementations
- [ ] No production impact (flag off by default)

---

### Phase 2: Parallel Implementation (Sprint 31)
**Goal**: Implement `useChat` alongside existing implementation

#### Tasks
1. **Create New Component**
   - File: `AIChatSidebarV2.tsx`
   - Use `useChat` hook
   - Match existing UX exactly
   - Selection context integration

2. **Conditional Rendering**
   ```typescript
   // App.tsx or parent component
   {settings.useVercelAiSdk ? (
     <AIChatSidebarV2 {...props} />
   ) : (
     <AIChatSidebar {...props} />
   )}
   ```

3. **Feature Parity Checklist**
   - [ ] Streaming display (word-by-word)
   - [ ] Selection context display
   - [ ] Clear selection button
   - [ ] Auto-scroll to latest message
   - [ ] Error states and retry
   - [ ] Loading indicators
   - [ ] Message history

4. **Side-by-Side Testing**
   - Test both implementations locally
   - Compare streaming performance
   - Verify UX matches
   - Check error handling

5. **Documentation**
   - Update component docs
   - Add migration notes
   - Document API route

**Deliverables:**
- ‚úÖ AIChatSidebarV2 complete
- ‚úÖ Feature parity achieved
- ‚úÖ Both implementations work

**Success Criteria:**
- [ ] Can toggle between old/new via feature flag
- [ ] New implementation matches old UX exactly
- [ ] No regressions in functionality

---

### Phase 3: Gradual Rollout (Sprint 32)
**Goal**: Roll out to production users incrementally

#### Rollout Strategy

**Week 1: Internal Testing (0%)**
- Enable for development team
- Monitor logs and errors
- Collect feedback

**Week 2: Beta Users (10%)**
- Random 10% of users
- Monitor error rates
- Compare performance metrics

**Week 3: Ramp Up (50%)**
- Increase to 50% of users
- Continue monitoring
- Be ready to rollback

**Week 4: Full Rollout (100%)**
- Enable for all users
- Default for new users
- Keep old implementation as fallback

#### Monitoring Checklist
- [ ] Error rate (target: <0.1%)
- [ ] Streaming performance (TTFT, tokens/sec)
- [ ] API latency (target: <100ms p95)
- [ ] User complaints/feedback
- [ ] Cost per request (OpenAI API usage)

#### Rollback Plan
If error rate >1% or critical bugs:
1. Set feature flag to `false` globally
2. Investigate logs and errors
3. Fix issues in staging
4. Resume rollout when stable

**Deliverables:**
- ‚úÖ 100% of users on new implementation
- ‚úÖ Metrics show stability
- ‚úÖ User feedback positive

**Success Criteria:**
- [ ] Error rate <0.1%
- [ ] No performance degradation
- [ ] User satisfaction maintained

---

### Phase 4: Cleanup & Optimization (Sprint 33)
**Goal**: Remove old implementation and optimize

#### Tasks
1. **Delete Old Code**
   - Remove `AIChatSidebar.tsx` (old version)
   - Remove custom streaming logic
   - Remove unused dependencies

2. **Rename Components**
   - `AIChatSidebarV2.tsx` ‚Üí `AIChatSidebar.tsx`
   - Update imports across codebase

3. **Remove Feature Flag**
   - Delete `USE_VERCEL_AI_SDK` setting
   - Clean up conditional rendering

4. **Optimization**
   - Review bundle size impact
   - Optimize API route performance
   - Add caching if beneficial

5. **Documentation Update**
   - Update architecture docs
   - Add ADR for AI SDK migration
   - Update README with new setup

6. **Code Review**
   - Final review of AI code
   - Ensure best practices
   - Add TODO comments for future features

**Deliverables:**
- ‚úÖ Old implementation removed
- ‚úÖ Codebase cleaned up
- ‚úÖ Documentation updated

**Success Criteria:**
- [ ] No references to old implementation
- [ ] TypeScript compiles without errors
- [ ] All tests passing
- [ ] Bundle size within budget

---

## üîß Technical Implementation Details

### 1. Netlify Function Structure

```typescript
// netlify/functions/ai-chat.ts
import { openai } from '@ai-sdk/openai'
import { streamText } from 'ai'
import type { Handler } from '@netlify/functions'

export const handler: Handler = async (event) => {
  // Validate request
  if (event.httpMethod !== 'POST') {
    return { statusCode: 405, body: 'Method Not Allowed' }
  }

  try {
    const { messages, fileId, selection, selectionRange } = JSON.parse(event.body || '{}')

    // Build context
    const systemMessage = buildSystemMessage(fileId, selection)

    // Stream response
    const result = streamText({
      model: openai('gpt-4o'),
      system: systemMessage,
      messages,
      temperature: 0.7,
      maxTokens: 2000
    })

    // Return streaming response
    return {
      statusCode: 200,
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive'
      },
      body: result.toDataStream()
    }
  } catch (error) {
    console.error('[AI Chat] Error:', error)
    return {
      statusCode: 500,
      body: JSON.stringify({ error: 'Internal server error' })
    }
  }
}

function buildSystemMessage(fileId?: string, selection?: string): string {
  return [
    'You are a helpful writing assistant for RiteMark markdown editor.',
    'Help users improve their writing, answer questions, and provide suggestions.',
    selection ? `User selected text: "${selection}"` : '',
    fileId ? `Working on document ID: ${fileId}` : ''
  ].filter(Boolean).join(' ')
}
```

### 2. Component Implementation

```typescript
// ritemark-app/src/components/ai/AIChatSidebarV2.tsx
import { useChat } from 'ai/react'
import type { EditorSelection } from '@/types/editor'

export function AIChatSidebarV2({
  editor,
  fileId,
  liveSelection,
  persistedSelection,
  onClearSelection
}: Props) {
  const { messages, input, handleInputChange, handleSubmit, isLoading, error } = useChat({
    api: '/api/ai-chat',
    body: {
      fileId,
      selection: persistedSelection?.text,
      selectionRange: {
        from: persistedSelection?.from,
        to: persistedSelection?.to
      }
    },
    onError: (error) => {
      console.error('[AI Chat] Error:', error)
      // Show user-friendly error message
    },
    onFinish: (message) => {
      console.log('[AI Chat] Message complete:', message.id)
      // Auto-scroll to bottom
    }
  })

  return (
    <div className="ai-chat-sidebar">
      {/* Selection context (same as before) */}
      {persistedSelection && (
        <div className="selection-context">
          <span>{persistedSelection.text}</span>
          <button onClick={onClearSelection}>Clear</button>
        </div>
      )}

      {/* Messages */}
      <div className="messages">
        {messages.map(m => (
          <div key={m.id} className={`message ${m.role}`}>
            {m.content}
          </div>
        ))}
      </div>

      {/* Error display */}
      {error && (
        <div className="error">
          <span>{error.message}</span>
          <button onClick={() => window.location.reload()}>Retry</button>
        </div>
      )}

      {/* Input form */}
      <form onSubmit={handleSubmit}>
        <textarea
          value={input}
          onChange={handleInputChange}
          placeholder="Ask AI assistant..."
          disabled={isLoading}
        />
        <button type="submit" disabled={isLoading || !input.trim()}>
          {isLoading ? 'Sending...' : 'Send'}
        </button>
      </form>
    </div>
  )
}
```

### 3. Feature Flag Integration

```typescript
// ritemark-app/src/contexts/SettingsContext.tsx
interface Settings {
  // ... existing settings
  experimental?: {
    useVercelAiSdk?: boolean  // Feature flag
  }
}

// ritemark-app/src/App.tsx
import { AIChatSidebar } from './components/ai/AIChatSidebar'
import { AIChatSidebarV2 } from './components/ai/AIChatSidebarV2'

const AIChatComponent = settings?.experimental?.useVercelAiSdk
  ? AIChatSidebarV2
  : AIChatSidebar

<AIChatComponent
  editor={editor}
  fileId={fileId}
  persistedSelection={lastSelection}
  onClearSelection={handleClearSelection}
/>
```

## üìä Success Metrics

### Performance Targets
- **Time to First Token (TTFT)**: <500ms (p95)
- **Streaming Speed**: ‚â•30 tokens/sec
- **Error Rate**: <0.1%
- **API Latency**: <100ms (p95)
- **Bundle Size Increase**: <20KB (gzipped)

### Quality Metrics
- **User Satisfaction**: No degradation
- **Bug Reports**: 0 critical bugs
- **Feature Parity**: 100% (all features working)

## ‚ö†Ô∏è Risk Assessment

### High Risk Items
1. **Backend Latency**: Extra hop (client ‚Üí Netlify ‚Üí OpenAI)
   - **Mitigation**: Deploy function to edge, optimize cold starts

2. **Breaking Changes**: Users notice UX differences
   - **Mitigation**: Exact UX replication, extensive testing

3. **Cost Increase**: Netlify function invocations
   - **Mitigation**: Monitor costs, optimize function cold starts

### Medium Risk Items
1. **Feature Flag Bugs**: Toggle not working correctly
   - **Mitigation**: Thorough testing, rollback plan

2. **Type Errors**: Vercel AI SDK types don't match our types
   - **Mitigation**: Create adapter types, test thoroughly

### Low Risk Items
1. **Bundle Size**: SDK adds ~15KB
   - **Impact**: Minimal (~0.3% of typical app bundle)

2. **Learning Curve**: Team unfamiliar with AI SDK patterns
   - **Mitigation**: Documentation, pair programming

## üéØ Go/No-Go Decision Criteria

### Go Criteria (All must be met)
- [x] Vercel AI SDK supports required features
- [x] Migration path is clear and incremental
- [x] Feature flag implementation ready
- [x] Netlify function tested and working
- [x] Team buy-in and understanding

### No-Go Criteria (Any triggers halt)
- [ ] Performance degradation >20%
- [ ] Error rate >1% in beta testing
- [ ] Bundle size increase >50KB
- [ ] Critical bugs found in staging
- [ ] User complaints spike

## üìù Post-Migration Opportunities

### Immediate Benefits (Sprint 34+)
1. **Provider Switching**: Easy to test Claude, Gemini
2. **Tool Calling**: Add function calling for editor actions
3. **Multi-Turn**: Better conversation context management
4. **Error Recovery**: Automatic retry on failures

### Future Features (Sprint 35+)
1. **Assistants API**: Persistent AI assistants per document
2. **Vision Support**: Analyze images in documents
3. **JSON Mode**: Structured outputs for features
4. **Streaming UI**: Advanced loading states, partial content

## ‚úÖ Final Recommendation

**PROCEED** with Vercel AI SDK migration using incremental rollout strategy.

**Rationale:**
- ‚úÖ Security improvement (API key on server)
- ‚úÖ Better developer experience (less code, better types)
- ‚úÖ Future-proof (easy to add features)
- ‚úÖ Industry standard (proven at scale)
- ‚úÖ Minimal risk (incremental approach)
- ‚úÖ Low cost (~15KB, <50ms latency)

**Next Steps:**
1. Review and approve this migration plan
2. Schedule Sprint 30 kickoff
3. Begin Phase 1: Foundation Setup

---

**Status**: ‚úÖ Complete - Awaiting approval
**Prepared By**: AI Research Team
**Date**: January 15, 2025
